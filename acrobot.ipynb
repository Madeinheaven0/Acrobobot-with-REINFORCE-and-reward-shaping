{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78462c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e146d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic(keras.Model):\n",
    "    \n",
    "    \"\"\"The neural network with two heads for the acrobot agent\n",
    "\n",
    "    Args:\n",
    "        keras (_type_): _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, n_actions:int, \n",
    "                 n1:int = 512, n2:int = 512, \n",
    "                 chkpt_dir='models/acrobot', name='acrobot_actor_critic'):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            input_dim (_type_): The dimension of the feature\n",
    "            n1 (int): The number of neurons of the the first layer\n",
    "            n2 (int): The number of neurons of the the second layer\n",
    "            n_actions (int): The number of possible actions\n",
    "            chkpt_dir (str, optional): Directory path. Defaults to 'models/acrobot'.\n",
    "            name (str, optional): Model's name. Defaults to 'acrobot_actor_critic'.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.model_name = name\n",
    "        self.chkpt_dir = chkpt_dir\n",
    "        self.chkpt_file = os.path.join(chkpt_dir, name + '.weights.h5')\n",
    "        \n",
    "        self.layer1 = keras.layers.Dense(n1, activation='elu', input_shape=input_dim)\n",
    "        self.layer2 = keras.layers.Dense(n2, activation='elu')\n",
    "        \n",
    "        self.actions = keras.layers.Dense(n_actions, activation=None)\n",
    "        self.value = keras.layers.Dense(1, activation=None)\n",
    "        \n",
    "    \n",
    "    def call(self, x): \n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            x (tf.Tensor): The input value\n",
    "\n",
    "        Returns:\n",
    "            tuple:\n",
    "                - The actions logit's probs\n",
    "                - The valuation of the actions \n",
    "        \"\"\"\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        \n",
    "        return self.actions(x), self.value(x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41ada093",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AcrobotAgent:\n",
    "    \"\"\"_summary_\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, env:gym.Env, gamma:float, lr:float=1e-5, delta:float=1.0) -> None:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            env (gym.Env): _description_\n",
    "            gamma (float): _description_\n",
    "            lr (float, optional): _description_. Defaults to 1e-5.\n",
    "            delta (float, optional): _description_. Defaults to 1.0.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.env = env\n",
    "\n",
    "        self.gamma = gamma\n",
    "\n",
    "        self.actor_critic: ActorCritic = ActorCritic(input_dim=[env.observation_space.shape[0]], \n",
    "                                                     n_actions=int(env.action_space.n))    \n",
    "        \n",
    "        self.actor_critic_optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "        self.actor_critic_loss = keras.losses.Huber(delta=delta)\n",
    "        \n",
    "        self.total_rewards = []\n",
    "        \n",
    "        self.buffer = {\n",
    "            'states': [],\n",
    "            'next_states': [],\n",
    "            'actions': [],\n",
    "            'dones': [],\n",
    "            'values': [],\n",
    "            'rewards': []\n",
    "        }\n",
    "        \n",
    "    \n",
    "    def reset_buffer(self):\n",
    "        \"\"\"_summary_\n",
    "        \"\"\"\n",
    "        self.buffer = {k:[] for k in self.buffer}    \n",
    "        \n",
    "    \n",
    "    def normalize_input(self, x:np.array):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            x (np.array): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        \n",
    "        return (x - np.mean(x)) / np.std(x)\n",
    "        \n",
    "        \n",
    "    def discount(self, rewards:list, dones:list):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            rewards (list): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        discounted_rewards = []\n",
    "        G = 0\n",
    "        for i in reversed(range(len(rewards))):\n",
    "            G =  rewards[i] + self.gamma * G * (1 - int(dones[i]))\n",
    "            discounted_rewards.insert(0, G)\n",
    "        return tf.convert_to_tensor(discounted_rewards, dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "    def normalize_discounts(self, rewards:list, dones:list):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            total_rewards (list): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        discounts = self.discount(rewards, dones)\n",
    "        \n",
    "        print(discounts.shape)\n",
    "        \n",
    "        mean = np.mean(discounts, axis=0)\n",
    "        std = np.std(discounts, axis=0)\n",
    "        \n",
    "        return (discounts - mean) / std \n",
    "    \n",
    "    \n",
    "    def play_one_step(self, state: np.array):\n",
    "        state = self.normalize_input(state)\n",
    "        state_tensor = tf.convert_to_tensor(state, dtype=tf.float32)\n",
    "        \n",
    "        state_tensor = tf.expand_dims(state_tensor, axis=0)\n",
    "        \n",
    "        actions_logs, value = self.actor_critic(state_tensor)\n",
    "        \n",
    "        best_action = tf.random.categorical(actions_logs, num_samples=1)\n",
    "        best_int_action = int(best_action.numpy()[0, 0])\n",
    "        \n",
    "        next_state, reward, terminated, truncated, _ = self.env.step(action=best_int_action)\n",
    "        \n",
    "        next_state = tf.convert_to_tensor(next_state, dtype=tf.float32)\n",
    "        \n",
    "        done = terminated or truncated\n",
    "        \n",
    "        self.buffer['states'].append(state)\n",
    "        self.buffer['next_states'].append(next_state)\n",
    "        self.buffer['actions'].append(best_action)\n",
    "        self.buffer['dones'].append(done)\n",
    "        self.buffer['values'].append(value)\n",
    "        self.buffer['rewards'].append(reward)\n",
    "        \n",
    "        return next_state, reward, done\n",
    "    \n",
    "    \n",
    "    def train_step(self):\n",
    "        \"\"\"_summary_\n",
    "        \"\"\"\n",
    "        states = tf.convert_to_tensor(self.buffer['states'], dtype=tf.float32)\n",
    "        actions = tf.convert_to_tensor(self.buffer['actions'], dtype=tf.float32)\n",
    "        dones = tf.convert_to_tensor(self.buffer['dones'], dtype=tf.float32)\n",
    "        rewards = tf.convert_to_tensor(self.buffer['rewards'], dtype=tf.float32)\n",
    "        \n",
    "        variables = self.actor_critic.trainable_variables\n",
    "        \n",
    "        discounted_normalize_rewards = self.normalize_discounts(rewards=rewards, dones=dones)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            actions_logs, values_predicted = self.actor_critic(states)\n",
    "            \n",
    "            advantages = tf.stop_gradient(discounted_normalize_rewards - tf.squeeze(values_predicted))\n",
    "            advantages = tf.expand_dims(advantages, axis=1)\n",
    "            \n",
    "            actions = tf.cast(actions, dtype=tf.int32)\n",
    "            # actor loss\n",
    "            logs = tf.gather_nd(actions_logs, actions)\n",
    "            actor_loss = -tf.reduce_sum(logs * advantages)\n",
    "            \n",
    "            # critic loss\n",
    "            critic_loss = self.actor_critic_loss(discounted_normalize_rewards, tf.squeeze(values_predicted))\n",
    "            \n",
    "            total_loss = actor_loss + critic_loss\n",
    "            \n",
    "        grads = tape.gradient(total_loss, variables)\n",
    "        self.actor_critic_optimizer.apply_gradients(zip(grads, variables))\n",
    "        \n",
    "    \n",
    "    def play_episode(self, n_step:int):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            n_step (_type_): _description_\n",
    "        \"\"\"\n",
    "        \n",
    "        state, _ = self.env.reset()\n",
    "        \n",
    "        episode_reward = 0\n",
    "        \n",
    "        for _ in range(n_step):\n",
    "            next_state, rewards, done = self.play_one_step(state)\n",
    "            episode_reward += rewards\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "            \n",
    "        self.total_rewards.append(episode_reward)\n",
    "        print(f\"Episode reward: {episode_reward}\")\n",
    "        \n",
    "    \n",
    "    def play_all_episode(self, n_episode:int, n_step:int):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            n_episode (int): _description_\n",
    "            n_step (int): _description_\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"-\" * 25, 'Training starts', 25 * '-')\n",
    "        \n",
    "        for episode in range(n_episode):\n",
    "            self.play_episode(n_step)\n",
    "            self.train_step()\n",
    "            self.reset_buffer()     \n",
    "        \n",
    "        print(\"-\" * 25, 'Training ends', 25 * '-')\n",
    "        \n",
    "        \n",
    "    def evaluate(self, n_episode:int, n_step:int):\n",
    "        total_rewards = []\n",
    "        \n",
    "        print(25 * '-', 'Evaluation start', '-' * 25)\n",
    "        \n",
    "        for _ in range(n_episode):\n",
    "            state, _ = self.env.reset()\n",
    "            episode_reward = 0\n",
    "            for _ in range(n_step):\n",
    "                state_normal = self.normalize_input(state)\n",
    "                state_tensor = tf.convert_to_tensor(state_normal, dtype=tf.float32)\n",
    "                state_tensor = tf.expand_dims(state_tensor, axis=0)\n",
    "                actions_log, _ = self.actor_critic(state_tensor)\n",
    "                best_action = tf.argmax(actions_log, axis=1)\n",
    "                best_action = int(best_action.numpy()[0])\n",
    "                next_state, reward, terminated, truncated = self.env.step(best_action)\n",
    "                done = terminated or truncated\n",
    "                episode_reward += reward\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "                \n",
    "                state = next_state\n",
    "                \n",
    "            total_rewards.append(episode_reward)\n",
    "        \n",
    "        print(25 * '-', 'Evaluation start', '-' * 25)    \n",
    "        \n",
    "        print(f\"The rewards mean is: {sum(total_rewards) / n_episode}\")\n",
    "        \n",
    "        return sum(total_rewards) / n_episode\n",
    "    \n",
    "    \n",
    "    def plot_rewards(self):\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.plot(self.total_rewards)\n",
    "        plt.title(\"Rewards per episode\")\n",
    "        plt.xlabel(\"Episodes\")\n",
    "        plt.ylabel(\"Rewards\")\n",
    "        plt.grid(True)\n",
    "        plt.show()   \n",
    "        \n",
    "    \n",
    "    def save_model(self):\n",
    "        \n",
    "        print(\"-\" * 25, 'Model is saving', '-' * 25)\n",
    "        \n",
    "        if os.path.exists(self.actor_critic.chkpt_dir):\n",
    "            self.actor_critic.save_weights(self.actor_critic.chkpt_file) \n",
    "            print(\"-\" * 25, 'Model saved', '-' * 25)\n",
    "        else:\n",
    "            os.makedirs(self.actor_critic.chkpt_dir)\n",
    "            self.actor_critic.save_weights(self.actor_critic.chkpt_file) \n",
    "            print(\"-\" * 25, 'Model is saving', '-' * 25)\n",
    "    \n",
    "    def load_model(self):\n",
    "        \n",
    "        print(\"-\" * 25, 'Model is loading', '-' * 25)\n",
    "        if os.path.exists(self.actor_critic.chkpt_dir):\n",
    "            self.actor_critic.load_weights(self.actor_critic.chkpt_file)\n",
    "        else:\n",
    "            os.makedirs(self.actor_critic.chkpt_dir)\n",
    "            print(\"The directory doesn't exist\")\n",
    "            print(\"Directory is created\")                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "13c8b245",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Acrobot-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6da7411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent(env: gym.Env, gamma:float, delta:float) -> AcrobotAgent:\n",
    "    return AcrobotAgent(env=env, gamma=gamma, delta=delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b0983a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(agent: AcrobotAgent, n_episode:int = 500, n_step:int = 200):\n",
    "    agent.play_all_episode(n_episode=n_episode, n_step=n_step)\n",
    "    agent.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f11fda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(agent: AcrobotAgent, n_episode:int, n_step:int):\n",
    "    agent.evaluate(n_episode=n_episode, n_step=n_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b7dae2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(env=env, gamma=0.975, delta=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1113bbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- Training starts -------------------------\n",
      "Episode reward: -150.0\n",
      "(300,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n",
      "Episode reward: -150.0\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "training_loop(agent=agent, n_episode=1000, n_step=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e19c4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- Evaluation start -------------------------\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Pack_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [1,3] != values[1].shape = [1,1] [Op:Pack] name: packed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgumentError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_episode\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_step\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 206\u001b[39m, in \u001b[36mAcrobotAgent.evaluate\u001b[39m\u001b[34m(self, n_episode, n_step)\u001b[39m\n\u001b[32m    204\u001b[39m state_tensor = tf.expand_dims(state_tensor, axis=\u001b[32m0\u001b[39m)\n\u001b[32m    205\u001b[39m actions_log = \u001b[38;5;28mself\u001b[39m.actor_critic(state_tensor)\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m best_action = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions_log\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m best_action = \u001b[38;5;28mint\u001b[39m(best_action.numpy()[\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m])\n\u001b[32m    208\u001b[39m next_state, reward, terminated, truncated = \u001b[38;5;28mself\u001b[39m.env.step(best_action)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\renforcement-LJl3_MAa-py3.12\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    155\u001b[39m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\renforcement-LJl3_MAa-py3.12\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6006\u001b[39m, in \u001b[36mraise_from_not_ok_status\u001b[39m\u001b[34m(e, name)\u001b[39m\n\u001b[32m   6004\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mraise_from_not_ok_status\u001b[39m(e, name) -> NoReturn:\n\u001b[32m   6005\u001b[39m   e.message += (\u001b[33m\"\u001b[39m\u001b[33m name: \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m6006\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m core._status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mInvalidArgumentError\u001b[39m: {{function_node __wrapped__Pack_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [1,3] != values[1].shape = [1,1] [Op:Pack] name: packed"
     ]
    }
   ],
   "source": [
    "agent.evaluate(n_episode=10, n_step=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c57f3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "renforcement-LJl3_MAa-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
